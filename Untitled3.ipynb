{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNZIw9a12j2Gp2N8rFORBn8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saketh223/IRS/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rZx8hrNHPlU"
      },
      "outputs": [],
      "source": [
        "           ASSIGNMENT-02 LAB\n",
        "\n",
        "Name: N.saketh\n",
        "Batch:26\n",
        "Date:20-01-2025\n",
        "\n",
        "\n",
        "\n",
        "{\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 0,\n",
        "  \"metadata\": {\n",
        "    \"colab\": {\n",
        "      \"provenance\": []\n",
        "    },\n",
        "    \"kernelspec\": {\n",
        "      \"name\": \"python3\",\n",
        "      \"display_name\": \"Python 3\"\n",
        "    },\n",
        "    \"language_info\": {\n",
        "      \"name\": \"python\"\n",
        "    }\n",
        "  },\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": 18,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"FdS5UOoX6pMp\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"import nltk\\n\",\n",
        "        \"from nltk.tokenize import word_tokenize\\n\",\n",
        "        \"from nltk.stem import PorterStemmer, SnowballStemmer\\n\",\n",
        "        \"from nltk.stem import WordNetLemmatizer\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"nltk.download('punkt')\\n\",\n",
        "        \"nltk.download('wordnet')\\n\",\n",
        "        \"nltk.download('omw-1.4')\\n\",\n",
        "        \"nltk.download('punkt_tab')\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\"\n",
        "        },\n",
        "        \"id\": \"8WcqULlL6utc\",\n",
        "        \"outputId\": \"610fa4c8-5465-4054-cfb0-ae3195696ce4\"\n",
        "      },\n",
        "      \"execution_count\": 19,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stderr\",\n",
        "          \"text\": [\n",
        "            \"[nltk_data] Downloading package punkt to /root/nltk_data...\\n\",\n",
        "            \"[nltk_data]   Package punkt is already up-to-date!\\n\",\n",
        "            \"[nltk_data] Downloading package wordnet to /root/nltk_data...\\n\",\n",
        "            \"[nltk_data]   Package wordnet is already up-to-date!\\n\",\n",
        "            \"[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\\n\",\n",
        "            \"[nltk_data]   Package omw-1.4 is already up-to-date!\\n\",\n",
        "            \"[nltk_data] Downloading package punkt_tab to /root/nltk_data...\\n\",\n",
        "            \"[nltk_data]   Package punkt_tab is already up-to-date!\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"execute_result\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": [\n",
        "              \"True\"\n",
        "            ]\n",
        "          },\n",
        "          \"metadata\": {},\n",
        "          \"execution_count\": 19\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"text = \\\"Jumping players were running swiftly in the fields.\\\"\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"F5xiOH_v6yNQ\"\n",
        "      },\n",
        "      \"execution_count\": 20,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"**Tokenization**\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"QVxzNRgs635L\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"tokens = word_tokenize(text)\\n\",\n",
        "        \"print(\\\"Tokenized Words:\\\")\\n\",\n",
        "        \"print(tokens)\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\"\n",
        "        },\n",
        "        \"id\": \"W75j2mB160rP\",\n",
        "        \"outputId\": \"7c346f51-3bfa-45c4-ee83-f73d9a978a54\"\n",
        "      },\n",
        "      \"execution_count\": 21,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"Tokenized Words:\\n\",\n",
        "            \"['Jumping', 'players', 'were', 'running', 'swiftly', 'in', 'the', 'fields', '.']\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"**Stemming using Porter Stemmer**\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"co_8-43D6-TB\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"porter_stemmer = PorterStemmer()\\n\",\n",
        "        \"porter_stems = [porter_stemmer.stem(word) for word in tokens]\\n\",\n",
        "        \"print(\\\"\\\\nStemming using Porter Stemmer:\\\")\\n\",\n",
        "        \"print(porter_stems)\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\"\n",
        "        },\n",
        "        \"id\": \"MGLI9Qly7D_k\",\n",
        "        \"outputId\": \"e1425e6c-3dc1-4a3e-9dce-ad855641ba7c\"\n",
        "      },\n",
        "      \"execution_count\": 22,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"\\n\",\n",
        "            \"Stemming using Porter Stemmer:\\n\",\n",
        "            \"['jump', 'player', 'were', 'run', 'swiftli', 'in', 'the', 'field', '.']\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"**Stemming using Snowball Stemmer**\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"BI2_n3lp7Kot\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"snowball_stemmer = SnowballStemmer(\\\"english\\\")\\n\",\n",
        "        \"snowball_stems = [snowball_stemmer.stem(word) for word in tokens]\\n\",\n",
        "        \"print(\\\"\\\\nStemming using Snowball Stemmer:\\\")\\n\",\n",
        "        \"print(snowball_stems)\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\"\n",
        "        },\n",
        "        \"id\": \"jYCh8f7h7Hr3\",\n",
        "        \"outputId\": \"8db46fbc-5f74-46e4-bfd6-2cfd4a98cba7\"\n",
        "      },\n",
        "      \"execution_count\": 23,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"\\n\",\n",
        "            \"Stemming using Snowball Stemmer:\\n\",\n",
        "            \"['jump', 'player', 'were', 'run', 'swift', 'in', 'the', 'field', '.']\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"**Lemmatization** **using** **WordNetLemmatizer** **bold text**\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"vtn4aDP37QGQ\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"lemmatizer = WordNetLemmatizer()\\n\",\n",
        "        \"lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens]\\n\",\n",
        "        \"print(\\\"\\\\nLemmatization using WordNetLemmatizer:\\\")\\n\",\n",
        "        \"print(lemmatized_words)\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\"\n",
        "        },\n",
        "        \"id\": \"fg2um7bD7TmL\",\n",
        "        \"outputId\": \"1f72ad01-7eab-4473-eee9-62649401310f\"\n",
        "      },\n",
        "      \"execution_count\": 24,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"\\n\",\n",
        "            \"Lemmatization using WordNetLemmatizer:\\n\",\n",
        "            \"['Jumping', 'player', 'were', 'running', 'swiftly', 'in', 'the', 'field', '.']\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"words = nltk.word_tokenize(text)\\n\",\n",
        "        \"lemmatizer = WordNetLemmatizer()\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"tfYGtjBY9frK\"\n",
        "      },\n",
        "      \"execution_count\": 14,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \" suffixes to remove\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"BB6_lRVi-lks\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"suffixes = [\\\"ing\\\", \\\"ed\\\", \\\"ly\\\", \\\"es\\\", \\\"s\\\"]\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"ANesEkKs9k8r\"\n",
        "      },\n",
        "      \"execution_count\": 25,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"print(\\\"Words with meaningful root words after removing suffixes:\\\\n\\\")\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\"\n",
        "        },\n",
        "        \"id\": \"XOlHVm0s9n-Y\",\n",
        "        \"outputId\": \"49bb7713-c028-4b9a-bbc3-84363140b017\"\n",
        "      },\n",
        "      \"execution_count\": 26,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"Words with meaningful root words after removing suffixes:\\n\",\n",
        "            \"\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"for word in words:\\n\",\n",
        "        \"    for suffix in suffixes:\\n\",\n",
        "        \"        if word.endswith(suffix):\\n\",\n",
        "        \"            root_word = word[: -len(suffix)]\\n\",\n",
        "        \"            from nltk.corpus import wordnet\\n\",\n",
        "        \"            if wordnet.synsets(root_word):\\n\",\n",
        "        \"                print(f\\\"Original Word: {word}, Root Word: {root_word}\\\")\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\"\n",
        "        },\n",
        "        \"id\": \"IhZA6roO9qyn\",\n",
        "        \"outputId\": \"68e06252-e0a3-42d7-aae5-386c1b438818\"\n",
        "      },\n",
        "      \"execution_count\": 28,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"Original Word: Jumping, Root Word: Jump\\n\",\n",
        "            \"Original Word: players, Root Word: player\\n\",\n",
        "            \"Original Word: swiftly, Root Word: swift\\n\",\n",
        "            \"Original Word: fields, Root Word: field\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\n"
      ]
    }
  ]
}